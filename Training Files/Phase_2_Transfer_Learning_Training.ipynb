{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oODe3X4ZyPdj"
      },
      "outputs": [],
      "source": [
        "#Connecting the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ALDllpEzyTpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the train directory\n",
        "train_dir='xxxxx'"
      ],
      "metadata": {
        "id": "MYdzdNrE0r-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os"
      ],
      "metadata": {
        "id": "Rf15iXp-yXk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfBDDJA9JRb"
      },
      "source": [
        "#Making a list with class label(name of plant) and file path in it\n",
        "plant = []\n",
        "plant_image = []\n",
        "for i in os.listdir(train_dir):\n",
        "    for image_filename in os.listdir(train_dir + i):\n",
        "        plant.append(i) # name of the plant\n",
        "        plant_image.append(i + '/' + image_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-wNXug9bad"
      },
      "source": [
        "#making a dataframe\n",
        "train_plants = pd.DataFrame(plants, columns=[\"plants\"])\n",
        "train_plants[\"plant Image\"] = plants_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialising 2 lists to store the path and class label\n",
        "image_paths=[]\n",
        "data_labels=[]"
      ],
      "metadata": {
        "id": "JljhU15hyykk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iterating over the previously created dataframe\n",
        "for i in range(len(train_plants)):\n",
        "  path=train_plants['plants Image'][i]\n",
        "  path=train_dir+path\n",
        "  label=train_plants['plants'][i]\n",
        "  image_paths.append(path)\n",
        "  data_labels.append(label)"
      ],
      "metadata": {
        "id": "1_28MfNVy1W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For storing the class labels for Training and Validation datasets\n",
        "train_data_class_list = []\n",
        "val_data_class_list = []\n",
        "\n",
        "# For storing the paths of images for Training and Validation datasets\n",
        "train_data_path_list = []\n",
        "val_data_path_list = []"
      ],
      "metadata": {
        "id": "Lc5vnzWey3PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "(train_data_path_list, val_data_path_list, train_data_class_list, val_data_class_list) = train_test_split(train_data_path_list,\n",
        "                                                                                                        train_data_class_list,\n",
        "                                                                                                        test_size = 0.285,\n",
        "                                                                                                        stratify = train_data_class_list,\n",
        "                                                                                                        random_state = 101)"
      ],
      "metadata": {
        "id": "1nghceRAy5_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLmkS54r93u8"
      },
      "source": [
        "len(train_data_path_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_27oU5uBCBPn"
      },
      "source": [
        "len(val_data_path_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E_29xG0CSED"
      },
      "source": [
        "#making a dataframe for train and validation\n",
        "df_train = pd.DataFrame({\"Path\":train_data_path_list,\"Class\":train_data_class_list})\n",
        "df_val = pd.DataFrame({\"Path\":val_data_path_list,\"Class\":val_data_class_list})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbxBITzQNoIG"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcKfhdwuCcyi"
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A0udDWzCf0U"
      },
      "source": [
        "len(pd.unique(df_train['Class']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox-0RH96C5DJ"
      },
      "source": [
        "len(pd.unique(df_val['Class']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW-APf0HC8RB"
      },
      "source": [
        "#using the pre defined function to initialise the class weights\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',classes=pd.unique(df_train['Class']),y=train_data_class_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ9ucTexDnfn"
      },
      "source": [
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ls-VXw6FHIk"
      },
      "source": [
        "class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXY8sbBuFOIn"
      },
      "source": [
        "# Initialize the initial values of different Hyperparameters\n",
        "INIT_LR = 0.0001        # learning rate\n",
        "EPOCHS = 5            # epochs\n",
        "BS = 32                # batch size\n",
        "DROPOUT = 0.5          # value of dropout\n",
        "MAXPOOL_SIZE = (2, 2)  # pool window size for Average Pooling Layer\n",
        "ROTATION_DEG = 15      # rotation degree for Data Augmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ob63Uy7Fo-a"
      },
      "source": [
        "#importing libraries to train the model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsimCuZ7Hxc0"
      },
      "source": [
        "#importing the base model as VGG 16\n",
        "baseModel = VGG16(weights = \"imagenet\", include_top = False, input_tensor = Input(shape=(100, 100, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F51qGYQ_ICht"
      },
      "source": [
        "#defining the head model over the base model\n",
        "headModel = baseModel.output\n",
        "headModel = Flatten(name = \"flatten\")(headModel)\n",
        "headModel = Dense(units = 128, activation = \"relu\")(headModel)\n",
        "headModel = Dropout(DROPOUT)(headModel)\n",
        "headModel = Dense(131, activation = \"softmax\")(headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB1smYWPIe2W"
      },
      "source": [
        "# Place the head FC model on top of the base model\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya5yUmzMLVON"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2PBbtyVLqqS"
      },
      "source": [
        "#initialising the optimizer and compiling the model\n",
        "opt = Adam(lr = INIT_LR, decay = INIT_LR / EPOCHS)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.AUC(name=\"auc\"),\n",
        "                                                                           tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "                                                                           tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "                                                                           tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "                                                                           tf.keras.metrics.FalseNegatives(name=\"fn\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyMDHQcrNgf8"
      },
      "source": [
        "tr_data = ImageDataGenerator(rotation_range = ROTATION_DEG, horizontal_flip = True, fill_mode = \"nearest\")\n",
        "val_data = ImageDataGenerator(rotation_range = ROTATION_DEG, horizontal_flip = True, fill_mode = \"nearest\")\n",
        "\n",
        "training_df = tr_data.flow_from_dataframe(df_train, x_col = \"Path\",y_col = \"Class\", batch_size = BS, target_size = (100, 100))\n",
        "validation_df = val_data.flow_from_dataframe(df_val, x_col = \"Path\",y_col = \"Class\", batch_size = BS, target_size = (100, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqolUrJEM7XA"
      },
      "source": [
        "#definining the directory location where the models and the logs will be stored\n",
        "ModelDir = \"yyyyyy\"\n",
        "\n",
        "LogDir = \"zzzzzzz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl8bprsBrdrj"
      },
      "source": [
        "import time\n",
        "LogPath = time.strftime(\"%Y%m%d-%H%M\", time.gmtime()) + \"-vgg16\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlt_J2UmOc1Z"
      },
      "source": [
        "# checkpointing\n",
        "from tensorflow import keras\n",
        "csv_logger = keras.callbacks.CSVLogger(LogDir + \"/\" + LogPath + \"-acc.csv\", append = True)\n",
        "\n",
        "entirecheckpointLast = keras.callbacks.ModelCheckpoint(filepath = ModelDir + \"/\" + LogPath + \"-entire-last.h5\", verbose = 0)\n",
        "\n",
        "entirecheckpointBest = keras.callbacks.ModelCheckpoint(filepath = ModelDir + \"/\" + LogPath + \"-entire-best.h5\", verbose = 1, save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-y2VwuoO-2H"
      },
      "source": [
        "#trainin the model\n",
        "History = model.fit(training_df,\n",
        "                 steps_per_epoch = len(df_train) // BS,\n",
        "                 validation_data = validation_df,\n",
        "                 validation_steps = len(df_val) // BS,\n",
        "                 epochs = EPOCHS,\n",
        "                 class_weight = class_weights,\n",
        "                 callbacks = [csv_logger, entirecheckpointLast, entirecheckpointBest]\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxTefnafQEkW"
      },
      "source": [
        "#Saving the model\n",
        "model_path = \"sssss\"\n",
        "model.save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}