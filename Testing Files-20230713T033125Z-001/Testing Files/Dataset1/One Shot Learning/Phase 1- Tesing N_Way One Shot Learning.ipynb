{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Phase 1- Tesing N_Way One Shot Learning.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yeM1kRdu_FPwPKSmly4kndaSS8Tfgjiz","authorship_tag":"ABX9TyP6BmmmzHINTRPXTfX4u/CU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3kHSywn19uyL"},"outputs":[],"source":["import re\n","import numpy as np\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","from keras import backend as K\n","from keras.layers import Activation\n","from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n","from keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import RMSprop,Adam\n","from keras import optimizers\n","\n","import matplotlib.image as mpimg \n","import matplotlib.pyplot as plt \n","\n","from keras import callbacks\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n","import os\n","from keras.models import Model,load_model\n","import json\n","from keras.models import model_from_json, load_model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["#Path of testing directory\n","path =  os.path.join('xxxx')"],"metadata":{"id":"XsW4H4Lq9zg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading the model\n","from keras.models import model_from_json\n","json_file = open('/content/drive/MyDrive/Major Project/Training Files/Dataset1/One Shot Learning/Model/model_architecture (1).json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"/content/drive/MyDrive/Major Project/Training Files/Dataset1/One Shot Learning/Model/model_weights.h5\")\n","print(\"Loaded model from disk\")"],"metadata":{"id":"zh0LE72OgHJr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model.summary()"],"metadata":{"id":"e-OUGr6GgbVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#defining a function to generate pairs for n way one shot learning\n","def n_way_pairs(n):\n","    #read the image\n","    img = mpimg.imread(path+'S' + str(1) + '/' + str(1) + '_100.jpg', 'rw+')\n","    #get the new size\n","    dim1 = image.shape[0]\n","    dim2 = image.shape[1]\n","\n","    count = 0\n","\n","    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n","    x_geuine_pair = np.zeros([1, 2, 1, dim1, dim2])\n","\n","    y_genuine = np.zeros([1,1])\n","\n","    ind1=np.random.randint(1,folder_count)\n","    image_index1=np.random.randint(1,image_count)\n","    image_index2=np.random.randint(1,image_count)\n","\n","    image1= mpimg.imread(path+'S'+str(ind1)+'/'+str(image_index1)+'_100.jpg','rw+')\n","    image2 = mpimg.imread(path+'S'+str(ind1)+'/'+str(image_index2)+'_100.jpg','rw+')\n","\n","    x_geuine_pair[0, 0, 0, :, :] = img1\n","    x_geuine_pair[0, 1, 0, :, :] = img2\n","    y_genuine[0] = 1\n","\n","    x_imposite_pair = np.zeros([n-1, 2, 1, dim1, dim2])\n","    y_imposite = np.zeros([n-1, 1])\n","\n","    count=0\n","\n","    for i in range(n-1):\n","      while True:\n","        ind2=np.random.randint(1,folder_count)\n","        if ind1 != ind2:\n","          break\n","      image_index3=np.random.randint(1,image_count)\n","\n","      image3=mpimg.imread(path+'S'+str(ind2)+'/'+str(image_index3)+'_100.jpg','rw+')\n","      \n","      x_imposite_pair[count, 0, 0, :, :] = img1\n","      x_imposite_pair[count, 1, 0, :, :] = img3\n","      #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n","      y_imposite[count] = 0\n","      count += 1\n","\n","    #now, concatenate, genuine pairs and imposite pair to get the whole data\n","    #print(x_geuine_pair.shape)\n","    #print(x_imposite_pair.shape)\n","    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n","    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n","\n","    return X, Y"],"metadata":{"id":"lo1Mn_6KA5W5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#defining a function to calculate the accuracy in n way one shot learning\n","def n_way_accuracy(steps,n):\n","  k=0\n","  for i in range(steps):\n","    x_test,y_test=n_way_pairs(n)\n","    preds=[]\n","    for j in range(n):\n","      pred=loaded_model.predict([x_test[j:j+1, 0], x_test[j:j+1, 1]])\n","      preds.append(pred)\n","    preds=np.array(preds)\n","    actual_index=np.argmax(np.array(y_test))\n","    predicted_index=np.argmin(preds)\n","    if actual_index==predicted_index:\n","      k+=1\n","  accuracy=(k/steps)*100\n","  \n","  return accuracy"],"metadata":{"id":"mSgjujzw_QyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["steps=100 #number of steps for n way one shot learning\n","history=[] #initialize the list to store accuracies \n","for i in range(5,40,5):\n","  n_accuracy=n_way_accuracy(steps,i)\n","  history.append(n_accuracy)\n","  print(f\"The accuracy for {i} way learning is :{n_accuracy}\")"],"metadata":{"id":"PziJcEi4VE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plotting the graph\n","ns=[5,10,15,20,25,30,35]\n","plt.plot(ns, history)\n","plt.xlabel(\"N in N-Way One shot learning\")\n","plt.ylabel(\"Accuracy\")\n","plt.title('Variation of accuracy by varying n in N-Way one shot learning')\n","\n","plt.show()"],"metadata":{"id":"ePdxz5TJ2drV"},"execution_count":null,"outputs":[]}]}